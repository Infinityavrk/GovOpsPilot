#!/usr/bin/env python3
"""
Bedrock UI Server
Flask server that provides a web UI for testing Bedrock Claude integration
"""

import os
import json
import time
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_from_directory
from flask_cors import CORS

# Set the bearer token
os.environ['AWS_BEARER_TOKEN_BEDROCK'] = os.environ.get("AWS_BEARER_TOKEN_BEDROCK")
import sys
import os
# Add paths for imports
sys.path.insert(0, os.path.join(project_root, 'integrations', 'genai'))
sys.path.insert(0, os.path.join(project_root, 'integrations'))

from enhanced_claude_sonnet_integration import EnhancedClaudeSonnetIntegration, get_backend_logs

# Set up Flask with correct template folder
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, '..', '..')
template_folder = os.path.join(project_root, 'ui', 'templates')

app = Flask(__name__, template_folder=template_folder)
CORS(app)

# Initialize Claude integration
claude_system = EnhancedClaudeSonnetIntegration()

@app.route('/')
def index():
    """Main UI page"""
    return render_template('bedrock_ui.html')

@app.route('/api/analyze', methods=['POST'])
def analyze_ticket():
    """Analyze ticket using Bedrock Claude"""
    try:
        data = request.get_json()
        ticket_text = data.get('ticket_text', '')
        context = data.get('context', {})
        
        if not ticket_text:
            return jsonify({'error': 'No ticket text provided'}), 400
        
        start_time = time.time()
        
        # Step 1: Comprehensive Analysis
        analysis = claude_system.analyze_ticket_with_claude_sonnet(ticket_text, context)
        
        # Step 2: Breach Prediction
        breach_pred = claude_system.predict_sla_breach_risk(analysis)
        
        # Step 3: Response Generation
        response = claude_system.generate_intelligent_response(analysis, context)
        
        processing_time = time.time() - start_time
        
        # Determine if Bedrock was used
        model_used = analysis.get('model_used', 'unknown')
        # Check for actual Bedrock models (Llama, Claude, etc.) and ensure it's not fallback
        bedrock_used = (
            ('llama' in model_used.lower() or 'claude' in model_used.lower() or 'us.meta' in model_used.lower()) 
            and 'fallback' not in model_used.lower() 
            and 'intelligent_fallback' != model_used
        )
        
        # Prepare response
        result = {
            'success': True,
            'processing_time': round(processing_time, 2),
            'bedrock_used': bedrock_used,
            'model_used': model_used,
            'analysis': analysis,
            'breach_prediction': breach_pred,
            'intelligent_response': response,
            'timestamp': datetime.now().isoformat()
        }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/status')
def system_status():
    """Get system status"""
    try:
        # Test actual Bedrock connectivity
        bedrock_working = False
        actual_model_used = 'fallback'
        
        try:
            # Quick test call to see what's actually working
            test_response = claude_system._call_claude_sonnet("Test", "test")
            if test_response.get('success'):
                bedrock_working = True
                actual_model_used = test_response.get('model_used', claude_system.model_id)
        except:
            pass
        
        status = {
            'bedrock_available': claude_system.bedrock_available,
            'bedrock_actually_working': bedrock_working,
            'model_id': claude_system.model_id,
            'fallback_model_id': claude_system.fallback_model_id,
            'actual_model_used': actual_model_used,
            'bearer_token_set': bool(os.environ.get('AWS_BEARER_TOKEN_BEDROCK')),
            'backend_status': {
                'primary_ai': 'Bedrock Llama 3.2' if bedrock_working else 'Intelligent Fallback',
                'model_name': actual_model_used,
                'accuracy': '95%' if bedrock_working else '85%',
                'response_time': '<3s' if bedrock_working else '<1s',
                'availability': '100%',
                'bedrock_detected': bedrock_working,
                'model_type': 'Llama 3.2 3B' if 'llama3-2-3b' in actual_model_used else 'Fallback'
            },
            'timestamp': datetime.now().isoformat()
        }
        
        return jsonify(status)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/examples')
def get_examples():
    """Get example tickets for testing"""
    examples = [
        {
            'title': 'Critical Aadhaar System Outage',
            'text': 'URGENT: Complete Aadhaar authentication system failure in Bhopal! Thousands of citizens cannot access government services. Banks unable to process KYC. This is a state emergency requiring immediate escalation!',
            'context': {
                'user_location': 'Bhopal, MP',
                'user_type': 'government_official',
                'technical_level': 'expert'
            }
        },
        {
            'title': 'Payment Gateway Issues',
            'text': 'Payment gateway experiencing timeout issues in Indore region. 30% transaction failure rate since morning. Merchants reporting revenue losses. Need urgent technical investigation.',
            'context': {
                'user_location': 'Indore, MP',
                'user_type': 'business_user',
                'technical_level': 'intermediate'
            }
        },
        {
            'title': 'Multi-language Citizen Issue',
            'text': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§ó‡§µ‡§æ‡§≤‡§ø‡§Ø‡§∞ ‡§∏‡•á ‡§π‡•Ç‡§Ç‡•§ Citizen portal ‡§¨‡§π‡•Å‡§§ slow ‡§π‡•à‡•§ Certificate download ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∞‡§π‡§æ‡•§ Please help! ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§',
            'context': {
                'user_location': 'Gwalior, MP',
                'user_type': 'citizen',
                'technical_level': 'basic',
                'language': 'Hindi-English'
            }
        },
        {
            'title': 'Positive Feedback',
            'text': 'Thank you for excellent improvements to digital services portal! New interface is user-friendly and certificate downloads are now instant. Citizens are very satisfied.',
            'context': {
                'user_location': 'Ujjain, MP',
                'user_type': 'citizen',
                'technical_level': 'intermediate'
            }
        }
    ]
    
    return jsonify(examples)

@app.route('/api/logs')
def get_logs():
    """Get recent backend logs"""
    try:
        logs = get_backend_logs()
        return jsonify({
            'success': True,
            'logs': logs,
            'count': len(logs),
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/license/analyze', methods=['POST'])
def analyze_license_portfolio():
    """Analyze license portfolio using AWS GenAI"""
    try:
        print("üîç License analysis endpoint called")
        data = request.get_json()
        license_data = data.get('license_data', [])
        
        print(f"üìä Received {len(license_data)} license assets for analysis")
        
        if not license_data:
            return jsonify({'error': 'No license data provided'}), 400
        
        start_time = time.time()
        
        # Initialize license optimization agent
        try:
            sys.path.insert(0, os.path.join(project_root, 'integrations'))
            from license_optimization_integration import LicenseOptimizationAgent
            license_agent = LicenseOptimizationAgent()
            print("‚úÖ License optimization agent initialized")
            
            # Analyze portfolio
            analysis_result = license_agent.analyze_license_portfolio(license_data)
            print(f"üìà Analysis completed with {len(analysis_result.get('recommendations', []))} recommendations")
            
            processing_time = time.time() - start_time
            
            # Prepare response
            result = {
                'success': True,
                'processing_time': round(processing_time, 2),
                'analysis': analysis_result,
                'recommendations': [
                    {
                        'id': rec['recommendation_id'],
                        'type': rec['recommendation_type'].replace('_', ' ').title(),
                        'description': rec['description'],
                        'savings': rec['potential_savings'],
                        'priority': rec['priority'],
                        'confidence': rec['confidence_score'],
                        'gemRequired': rec['gem_integration_required'],
                        'assetId': rec['asset_id']
                    } for rec in analysis_result.get('recommendations', [])
                ],
                'timestamp': datetime.now().isoformat()
            }
            
            print("‚úÖ License analysis response prepared successfully")
            return jsonify(result)
            
        except ImportError as ie:
            print(f"‚ö†Ô∏è Import error: {ie}")
            # Fallback if license optimization module is not available
            return jsonify({
                'success': False,
                'error': 'License optimization module not available',
                'fallback': True,
                'timestamp': datetime.now().isoformat()
            }), 503
        
    except Exception as e:
        print(f"‚ùå License analysis error: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/self-service/chat', methods=['POST'])
def self_service_chat():
    """Handle self-service chat requests with multilingual support"""
    try:
        print("üí¨ Self-service chat endpoint called")
        data = request.get_json()
        user_message = data.get('message', '')
        language = data.get('language', 'en')
        chat_history = data.get('chat_history', [])
        
        print(f"üìù User message: {user_message[:100]}...")
        print(f"üåê Language: {language}")
        
        if not user_message:
            return jsonify({'error': 'No message provided'}), 400
        
        start_time = time.time()
        
        try:
            # Use the same Claude integration for self-service
            ai_response = claude_system._call_claude_sonnet(
                create_self_service_prompt(user_message, language, chat_history),
                'self_service_chat'
            )
            
            if ai_response['success']:
                # Extract response from AI
                response_text = extract_response_from_ai(ai_response['content'], language)
                processing_time = time.time() - start_time
                
                print(f"‚úÖ AI response generated in {processing_time:.2f}s")
                
                return jsonify({
                    'success': True,
                    'response': response_text,
                    'language': language,
                    'processing_time': round(processing_time, 2),
                    'model_used': ai_response['model_used'],
                    'timestamp': datetime.now().isoformat()
                })
            else:
                # Fallback response
                return jsonify({
                    'success': False,
                    'error': 'AI service unavailable',
                    'fallback': True,
                    'timestamp': datetime.now().isoformat()
                }), 503
                
        except Exception as ai_error:
            print(f"‚ö†Ô∏è AI service error: {ai_error}")
            return jsonify({
                'success': False,
                'error': 'AI service unavailable',
                'fallback': True,
                'timestamp': datetime.now().isoformat()
            }), 503
        
    except Exception as e:
        print(f"‚ùå Self-service chat error: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

def create_self_service_prompt(user_message, language, chat_history):
    """Create a prompt for self-service chat with multilingual support"""
    
    # Context about government services
    context = """You are an expert AI assistant for Indian government digital services. You have deep knowledge of:
    
    - UIDAI (Aadhaar): Identity verification, card download, updates, authentication issues
    - MeiTY: Payment gateway, transaction failures, billing, financial services  
    - DigitalMP: Digital service portals, online applications, citizen services
    - eDistrict: Certificate services, document verification, application tracking
    - MPOnline: Integrated government services, multi-department coordination
    
    You can respond in English, Hindi, or mixed language based on user preference.
    Provide helpful, accurate, and actionable information."""
    
    # Language-specific instructions
    if language == 'hi':
        language_instruction = "Respond primarily in Hindi (Devanagari script). Be helpful and respectful."
    elif language == 'mixed':
        language_instruction = "You can respond in both English and Hindi as appropriate. Use the language that best serves the user."
    else:
        language_instruction = "Respond in clear, simple English. Be helpful and professional."
    
    # Chat history context
    history_context = ""
    if chat_history:
        history_context = "\nRecent conversation:\n"
        for msg in chat_history[-3:]:  # Last 3 messages
            history_context += f"{msg['sender']}: {msg['message']}\n"
    
    prompt = f"""{context}

{language_instruction}

{history_context}

User Question: {user_message}

Provide a helpful, accurate response about government services. If you don't know something specific, guide the user to the appropriate official channel or website. Keep responses concise but informative.

Response:"""
    
    return prompt

def extract_response_from_ai(ai_content, language):
    """Extract and clean the AI response"""
    
    # Remove any prompt echoing or formatting
    response = ai_content.strip()
    
    # Remove common AI prefixes
    prefixes_to_remove = [
        "Response:", "Answer:", "Reply:", "AI Response:",
        "‡§â‡§§‡•ç‡§§‡§∞:", "‡§ú‡§µ‡§æ‡§¨:", "Response in Hindi:"
    ]
    
    for prefix in prefixes_to_remove:
        if response.startswith(prefix):
            response = response[len(prefix):].strip()
    
    # Ensure response is not too long
    if len(response) > 1000:
        response = response[:1000] + "..."
    
    # Default fallback if response is empty
    if not response:
        if language == 'hi':
            response = "‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã‡§ó‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§î‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§∏‡•á ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
        else:
            response = "I'd be happy to help you! Please provide more details about your question."
    
    return response

if __name__ == '__main__':
    print("üöÄ Starting Bedrock UI Server...")
    print("ü§ñ Bedrock Claude integration ready")
    print("üåê Access the UI at: http://localhost:5001")
    print("=" * 50)
    
    app.run(debug=True, host='0.0.0.0', port=5001)
